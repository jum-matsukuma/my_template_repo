{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploratory Data Analysis\n",
    "\n",
    "**Competition**: [Competition Name]  \n",
    "**Author**: [Your Name]  \n",
    "**Date**: [Date]  \n",
    "**Objective**: Initial exploration and understanding of the competition dataset\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Basic Info](#1-data-loading-and-basic-info)\n",
    "2. [Target Variable Analysis](#2-target-variable-analysis)\n",
    "3. [Feature Overview](#3-feature-overview)\n",
    "4. [Missing Values Analysis](#4-missing-values-analysis)\n",
    "5. [Correlation Analysis](#5-correlation-analysis)\n",
    "6. [Distribution Analysis](#6-distribution-analysis)\n",
    "7. [Initial Insights](#7-initial-insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about the datasets\n",
    "print(\"=== TRAIN DATA INFO ===\")\n",
    "train_df.info()\n",
    "print(\"\\n=== TRAIN DATA DESCRIPTION ===\")\n",
    "display(train_df.describe())\n",
    "print(\"\\n=== FIRST FEW ROWS ===\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column (update based on competition)\n",
    "target_col = 'target'  # Update this\n",
    "feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols[:10]}...\")  # Show first 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "print(\"=== TARGET VARIABLE STATISTICS ===\")\n",
    "print(train_df[target_col].describe())\n",
    "print(f\"\\nMissing values: {train_df[target_col].isnull().sum()}\")\n",
    "print(f\"Unique values: {train_df[target_col].nunique()}\")\n",
    "\n",
    "# Check if binary/multiclass classification or regression\n",
    "if train_df[target_col].nunique() <= 20:\n",
    "    print(f\"\\nValue counts:\\n{train_df[target_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distribution plot\n",
    "if train_df[target_col].nunique() > 20:  # Continuous target\n",
    "    axes[0].hist(train_df[target_col], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_title('Target Distribution')\n",
    "    axes[0].set_xlabel(target_col)\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Box plot\n",
    "    axes[1].boxplot(train_df[target_col])\n",
    "    axes[1].set_title('Target Box Plot')\n",
    "    axes[1].set_ylabel(target_col)\n",
    "else:  # Categorical target\n",
    "    value_counts = train_df[target_col].value_counts()\n",
    "    axes[0].bar(value_counts.index.astype(str), value_counts.values)\n",
    "    axes[0].set_title('Target Distribution')\n",
    "    axes[0].set_xlabel(target_col)\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')\n",
    "    axes[1].set_title('Target Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features by data type\n",
    "numerical_features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from numerical features if present\n",
    "if target_col in numerical_features:\n",
    "    numerical_features.remove(target_col)\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features[:10]}...\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics summary\n",
    "feature_summary = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Type': train_df.dtypes,\n",
    "    'Missing_Count': train_df.isnull().sum(),\n",
    "    'Missing_Percent': (train_df.isnull().sum() / len(train_df)) * 100,\n",
    "    'Unique_Values': train_df.nunique(),\n",
    "    'Unique_Percent': (train_df.nunique() / len(train_df)) * 100\n",
    "})\n",
    "\n",
    "feature_summary = feature_summary.sort_values('Missing_Percent', ascending=False)\n",
    "display(feature_summary.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values heatmap\n",
    "missing_data = train_df.isnull().sum().sort_values(ascending=False)\n",
    "missing_data = missing_data[missing_data > 0]\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x=missing_data.values, y=missing_data.index)\n",
    "    plt.title('Missing Values by Feature')\n",
    "    plt.xlabel('Number of Missing Values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Missing values pattern\n",
    "    if len(missing_data) <= 20:  # Only show if manageable number\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.heatmap(train_df[missing_data.index].isnull(), \n",
    "                   cbar=True, yticklabels=False, cmap='viridis')\n",
    "        plt.title('Missing Values Pattern')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\nelse:\n",
    "    print(\"No missing values found in the training data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "if len(numerical_features) > 0:\n",
    "    correlations = train_df[numerical_features + [target_col]].corr()[target_col].sort_values(ascending=False)\n",
    "    correlations = correlations.drop(target_col)  # Remove self-correlation\n",
    "    \n",
    "    plt.figure(figsize=(10, max(6, len(correlations) * 0.3)))\n",
    "    sns.barplot(x=correlations.values, y=correlations.index)\n",
    "    plt.title('Feature Correlation with Target')\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 correlations with target:\")\n",
    "    print(correlations.head(10))\n",
    "    print(\"\\nBottom 10 correlations with target:\")\n",
    "    print(correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (for top features)\n",
    "if len(numerical_features) > 0:\n",
    "    # Select top correlated features for heatmap\n",
    "    top_features = correlations.abs().sort_values(ascending=False).head(15).index.tolist()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = train_df[top_features + [target_col]].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Correlation Heatmap - Top Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features distribution\n",
    "if len(numerical_features) > 0:\n",
    "    n_features_to_plot = min(12, len(numerical_features))\n",
    "    features_to_plot = numerical_features[:n_features_to_plot]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=(n_features_to_plot + 2) // 3, ncols=3, \n",
    "                            figsize=(15, 5 * ((n_features_to_plot + 2) // 3)))\n",
    "    axes = axes.ravel() if n_features_to_plot > 3 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features_to_plot):\n",
    "        if i < len(axes):\n",
    "            train_df[feature].hist(bins=30, alpha=0.7, ax=axes[i], edgecolor='black')\n",
    "            axes[i].set_title(f'{feature} Distribution')\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "if len(categorical_features) > 0:\n",
    "    for feature in categorical_features[:5]:  # Show first 5 categorical features\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        value_counts = train_df[feature].value_counts().head(20)  # Top 20 categories\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts.plot(kind='bar')\n",
    "        plt.title(f'{feature} - Value Counts')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Target by category (if not too many categories)\n",
    "        if train_df[feature].nunique() <= 20:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            target_by_cat = train_df.groupby(feature)[target_col].mean().sort_values()\n",
    "            target_by_cat.plot(kind='bar')\n",
    "            plt.title(f'Average {target_col} by {feature}')\n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel(f'Average {target_col}')\n",
    "            plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initial Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key insights\n",
    "print(\"=== INITIAL EDA INSIGHTS ===\")\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Training samples: {len(train_df):,}\")\n",
    "print(f\"   - Test samples: {len(test_df):,}\")\n",
    "print(f\"   - Total features: {len(feature_cols)}\")\n",
    "print(f\"   - Numerical features: {len(numerical_features)}\")\n",
    "print(f\"   - Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "print(f\"\\n2. Target Variable:\")\n",
    "if train_df[target_col].nunique() > 20:\n",
    "    print(f\"   - Type: Continuous (Regression problem)\")\n",
    "    print(f\"   - Range: {train_df[target_col].min():.3f} to {train_df[target_col].max():.3f}\")\n",
    "    print(f\"   - Mean: {train_df[target_col].mean():.3f}\")\n",
    "    print(f\"   - Std: {train_df[target_col].std():.3f}\")\nelse:\n",
    "    print(f\"   - Type: Categorical (Classification problem)\")\n",
    "    print(f\"   - Classes: {train_df[target_col].nunique()}\")\n",
    "    class_dist = train_df[target_col].value_counts(normalize=True)\n",
    "    print(f\"   - Distribution: {dict(class_dist)}\")\n",
    "\n",
    "print(f\"\\n3. Data Quality:\")\n",
    "total_missing = train_df.isnull().sum().sum()\n",
    "print(f\"   - Total missing values: {total_missing:,}\")\n",
    "print(f\"   - Features with missing values: {(train_df.isnull().sum() > 0).sum()}\")\n",
    "if total_missing > 0:\n",
    "    worst_feature = train_df.isnull().sum().idxmax()\n",
    "    worst_missing = train_df.isnull().sum().max()\n",
    "    print(f\"   - Worst feature: {worst_feature} ({worst_missing} missing, {worst_missing/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "if len(numerical_features) > 0:\n",
    "    print(f\"\\n4. Feature Correlations:\")\n",
    "    print(f\"   - Strongest positive correlation: {correlations.iloc[0]:.3f} ({correlations.index[0]})\")\n",
    "    print(f\"   - Strongest negative correlation: {correlations.iloc[-1]:.3f} ({correlations.index[-1]})\")\n",
    "    strong_correlations = correlations[abs(correlations) > 0.5]\n",
    "    print(f\"   - Features with |correlation| > 0.5: {len(strong_correlations)}\")\n",
    "\n",
    "print(f\"\\n5. Next Steps:\")\n",
    "print(f\"   - Detailed feature engineering analysis\")\n",
    "print(f\"   - Missing value imputation strategy\")\n",
    "print(f\"   - Outlier detection and treatment\")\n",
    "print(f\"   - Feature selection and dimensionality analysis\")\n",
    "print(f\"   - Train/Test distribution comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save insights to file for future reference\n",
    "insights = {\n",
    "    'dataset_shape': {'train': train_df.shape, 'test': test_df.shape},\n",
    "    'target_info': {\n",
    "        'name': target_col,\n",
    "        'type': 'continuous' if train_df[target_col].nunique() > 20 else 'categorical',\n",
    "        'unique_values': int(train_df[target_col].nunique()),\n",
    "        'missing_values': int(train_df[target_col].isnull().sum())\n",
    "    },\n",
    "    'feature_counts': {\n",
    "        'total': len(feature_cols),\n",
    "        'numerical': len(numerical_features),\n",
    "        'categorical': len(categorical_features)\n",
    "    },\n",
    "    'data_quality': {\n",
    "        'total_missing': int(total_missing),\n",
    "        'features_with_missing': int((train_df.isnull().sum() > 0).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../../configs/eda_insights.json', 'w') as f:\n",
    "    json.dump(insights, f, indent=2)\n",
    "\n",
    "print(\"Initial EDA insights saved to configs/eda_insights.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}